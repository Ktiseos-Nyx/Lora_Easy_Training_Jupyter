{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ **Unified LoRA Trainer** - One Notebook to Rule Them All!\n",
    "\n",
    "**âœ¨ Auto-detects your model type and uses the optimal Kohya training script automatically!**\n",
    "\n",
    "## ğŸ§  **Smart Detection System**\n",
    "- **SD 1.5/2.0**: Uses `train_network.py` \n",
    "- **SDXL**: Uses `sdxl_train_network.py`\n",
    "- **Flux**: Uses `flux_train_network.py` with bf16 precision\n",
    "- **SD3**: Uses `sd3_train_network.py` with T5 text encoder support\n",
    "\n",
    "## ğŸ¨ **What This Notebook Does**\n",
    "1. **Cell 1**: Environment Setup & Backend Installation\n",
    "2. **Cell 2**: Universal Training Configuration (auto-adapts to your model)\n",
    "3. **Cell 3**: Training Execution & Monitoring\n",
    "4. **Cell 4**: Post-Training Utilities (resize, upload, etc.)\n",
    "\n",
    "## ğŸ”¬ **For Advanced Users**\n",
    "Need specialized features? Check out:\n",
    "- `Flux_SD3_Trainer.ipynb` - T5 text encoder fine-tuning\n",
    "- `T5_Trainer.ipynb` - Dedicated T5 training\n",
    "- Future: SimpleTuner notebooks for bleeding-edge models\n",
    "\n",
    "---\n",
    "**ğŸ’¡ Powered by Kohya's battle-tested library system + our user-friendly widgets!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 1:** ğŸ—ï¸ Environment Setup & Backend Installation\n",
    "\n",
    "**Run this first!** Sets up the training environment and downloads the Kohya backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 1:** ğŸ” Environment Validation & Quick Setup\n# Auto-validates that installer.py did its job correctly\n# Only shows setup options if something needs fixing\n\nimport os\nimport sys\nfrom shared_managers import get_setup_manager\nimport ipywidgets as widgets\nfrom IPython.display import display\n\nprint(\"ğŸ¯ UNIFIED LORA TRAINER - Environment Check...\")\nprint(\"âœ¨ Validating installation completed by installer.py\")\nprint()\n\n# Quick environment validation\nsetup_manager = get_setup_manager()\nbackend_path = os.path.join(os.getcwd(), \"trainer\", \"derrian_backend\")\n\nif os.path.exists(backend_path) and os.path.exists(os.path.join(backend_path, \"sd_scripts\")):\n    print(\"âœ… Backend installation: OK\")\n    print(\"âœ… Kohya sd_scripts: OK\")\n    print(\"âœ… Ready for training!\")\n    print()\n    print(\"ğŸ’¡ Environment is ready! Proceed to Cell 2 for training configuration.\")\nelse:\n    print(\"âš ï¸ Backend not properly installed!\")\n    print(\"ğŸ”§ Run: python installer.py\")\n    print(\"ğŸ“– Or check installation documentation\")\n    \n    # Only show setup widget if there's an issue\n    from widgets.setup_widget import SetupWidget\n    from shared_managers import get_model_manager\n    \n    print(\"ğŸš¨ Emergency setup widget (use only if installer.py failed):\")\n    setup_widget = SetupWidget(setup_manager, get_model_manager())\n    setup_widget.display()\n\nprint()\nprint(\"ğŸ’¡ This notebook automatically detects your model type and uses:\")\nprint(\"   â€¢ SD 1.5/2.0 â†’ train_network.py\")\nprint(\"   â€¢ SDXL â†’ sdxl_train_network.py\") \nprint(\"   â€¢ Flux â†’ flux_train_network.py\")\nprint(\"   â€¢ SD3 â†’ sd3_train_network.py\")\n\n# Always provide diagnostic button for troubleshooting\nprint()\nprint(\"ğŸ” Need to troubleshoot? Use the diagnostic button below:\")\n\ndiagnostic_button = widgets.Button(\n    description=\"ğŸ” Run Full Diagnostics\",\n    button_style='info',\n    tooltip=\"Run comprehensive system diagnostics\"\n)\ndiagnostic_output = widgets.Output()\n\ndef run_full_diagnostics(b):\n    diagnostic_output.clear_output()\n    with diagnostic_output:\n        print(\"ğŸ” COMPREHENSIVE SYSTEM DIAGNOSTICS\")\n        print(\"=\" * 50)\n        \n        # Use the setup widget's diagnostic capabilities\n        from widgets.setup_widget import SetupWidget\n        from shared_managers import get_model_manager\n        \n        setup_widget = SetupWidget(setup_manager, get_model_manager())\n        \n        # Run container detection\n        container_info = setup_widget._detect_container_environment()\n        print(f\"Environment: {container_info['environment']}\")\n        print(f\"Provider: {container_info['provider_details']['name']}\")\n        print(f\"GPU Count: {container_info['gpu_count']}\")\n        print(f\"GPU Names: {container_info['gpu_names']}\")\n        \n        # Check key paths\n        print(\"\\nğŸ“ PATH CHECKS:\")\n        paths_to_check = [\n            (\"Project Root\", os.getcwd()),\n            (\"Backend\", backend_path),\n            (\"SD Scripts\", os.path.join(backend_path, \"sd_scripts\")),\n            (\"LyCORIS\", os.path.join(backend_path, \"lycoris\")),\n        ]\n        \n        for name, path in paths_to_check:\n            status = \"âœ… EXISTS\" if os.path.exists(path) else \"âŒ MISSING\"\n            print(f\"   {name}: {status}\")\n            if os.path.exists(path):\n                print(f\"      â†’ {path}\")\n        \n        # Check system dependencies\n        print(\"\\nğŸ”§ SYSTEM DEPENDENCIES:\")\n        import shutil\n        deps = [\"python\", \"git\", \"aria2c\"]\n        for dep in deps:\n            status = \"âœ… FOUND\" if shutil.which(dep) else \"âŒ MISSING\"\n            print(f\"   {dep}: {status}\")\n        \n        # Check Python packages\n        print(\"\\nğŸ“¦ KEY PYTHON PACKAGES:\")\n        packages = [\"torch\", \"transformers\", \"accelerate\", \"diffusers\", \"bitsandbytes\"]\n        for pkg in packages:\n            try:\n                __import__(pkg)\n                print(f\"   {pkg}: âœ… INSTALLED\")\n            except ImportError:\n                print(f\"   {pkg}: âŒ MISSING\")\n        \n        print(\"\\nâœ… Diagnostic complete!\")\n\ndiagnostic_button.on_click(run_full_diagnostics)\ndisplay(diagnostic_button, diagnostic_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 2:** ğŸ¨ Universal Training Configuration\n",
    "\n",
    "**The magic happens here!** Configure your training settings and the system will automatically:\n",
    "- Detect your model type from the model path\n",
    "- Select the optimal training script\n",
    "- Apply architecture-specific optimizations\n",
    "- Use the right precision settings (fp16 for SD/SDXL, bf16 for Flux, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 2:** Universal Training Configuration Widget\n",
    "# This auto-adapts based on your model type - no manual configuration needed!\n",
    "# Uses the new Kohya-powered backend with automatic model detection\n",
    "\n",
    "from core.refactored_training_manager import HybridTrainingManager\n",
    "from widgets.training_widget import TrainingWidget\n",
    "\n",
    "print(\"ğŸ¯ UNIVERSAL TRAINING CONFIGURATION\")\n",
    "print(\"âœ¨ Smart model detection enabled\")\n",
    "print(\"ğŸ”§ Kohya optimization system active\")\n",
    "print()\n",
    "\n",
    "# Create the unified training manager (uses Kohya backend with auto-detection)\n",
    "training_manager = HybridTrainingManager()\n",
    "training_widget = TrainingWidget(training_manager)\n",
    "\n",
    "# Display the universal configuration widget\n",
    "training_widget.display()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ Tips:\")\n",
    "print(\"   â€¢ Just select your model file - type detection is automatic!\")\n",
    "print(\"   â€¢ Default settings are optimized for each architecture\")\n",
    "print(\"   â€¢ All Kohya optimizers and features available\")\n",
    "print(\"   â€¢ CAME optimizer auto-detects if available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 3:** ğŸš€ Training Execution & Real-time Monitoring\n",
    "\n",
    "**Ready to train?** This cell:\n",
    "- Uses the configuration from Cell 2\n",
    "- Automatically selects the right Kohya training script\n",
    "- Shows real-time progress with loss curves and metrics\n",
    "- Handles all the technical details behind the scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 3:** Training Execution & Monitoring\n",
    "# Run this AFTER configuring your settings in Cell 2\n",
    "# The system automatically uses the optimal training script for your model type\n",
    "\n",
    "from shared_managers import get_training_manager\n",
    "from widgets.training_monitor_widget import TrainingMonitorWidget\n",
    "\n",
    "print(\"ğŸš€ UNIFIED TRAINING SYSTEM - Starting...\")\n",
    "print(\"ğŸ§  Model type will be auto-detected from your model file\")\n",
    "print(\"âš¡ Optimal Kohya script will be selected automatically\")\n",
    "print(\"ğŸ“Š Real-time monitoring enabled\")\n",
    "print()\n",
    "\n",
    "# Use the shared training manager instance (same as Cell 2)\n",
    "training_monitor = TrainingMonitorWidget(training_manager_instance=get_training_manager())\n",
    "\n",
    "# Display the monitoring widget\n",
    "training_monitor.display()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ What happens automatically:\")\n",
    "print(\"   âœ… Model type detection from your model path\")\n",
    "print(\"   âœ… Optimal training script selection\")\n",
    "print(\"   âœ… Architecture-specific optimizations\")\n",
    "print(\"   âœ… Memory and precision settings\")\n",
    "print(\"   âœ… Real-time progress tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **CELL 4:** ğŸ› ï¸ Post-Training Utilities\n",
    "\n",
    "**Training complete?** Use these utilities to:\n",
    "- Resize your LoRA for different sizes\n",
    "- Upload to HuggingFace Hub\n",
    "- Test your trained LoRA\n",
    "- Organize your training outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **CELL 4:** Post-Training Utilities\n",
    "# Resize, upload, and manage your trained LoRAs\n",
    "# Works with all model types automatically\n",
    "\n",
    "from shared_managers import get_utilities_manager\n",
    "from widgets.utilities_widget import UtilitiesWidget\n",
    "\n",
    "print(\"ğŸ› ï¸ POST-TRAINING UTILITIES\")\n",
    "print(\"ğŸ“¦ LoRA management and optimization tools\")\n",
    "print(\"â˜ï¸ HuggingFace Hub integration\")\n",
    "print()\n",
    "\n",
    "# Create utilities widget\n",
    "utilities_widget = UtilitiesWidget(get_utilities_manager())\n",
    "utilities_widget.display()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ‰ Training Complete! Your LoRA is ready to use!\")\n",
    "print(\"ğŸ’¡ For advanced features, check out the specialized notebooks:\")\n",
    "print(\"   â€¢ Flux_SD3_Trainer.ipynb - T5 text encoder training\")\n",
    "print(\"   â€¢ Future SimpleTuner integration for bleeding-edge models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **ğŸ“Š Optional: LoRA Step Calculator**\n",
    "\n",
    "**Want to optimize your training parameters?** This calculator helps you find the perfect settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **OPTIONAL:** LoRA Step Calculator\n",
    "# Calculate optimal training steps, learning rates, and batch sizes\n",
    "# Works for all model architectures\n",
    "\n",
    "from shared_managers import create_widget\n",
    "\n",
    "print(\"ğŸ“Š LORA STEP CALCULATOR\")\n",
    "print(\"ğŸ§® Optimize your training parameters\")\n",
    "print()\n",
    "\n",
    "calculator_widget = create_widget('calculator')\n",
    "calculator_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **ğŸ—‚ï¸ Optional: File Management**\n",
    "\n",
    "**Need to manage your training files?** Upload datasets, organize outputs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **OPTIONAL:** File Management Utilities\n# Upload datasets, manage training files, organize outputs\n\nfrom shared_managers import create_widget\n\nprint(\"ğŸ—‚ï¸ FILE MANAGEMENT SYSTEM\")\nprint(\"ğŸ“ Upload and organize training data\")\nprint()\n\nfile_manager_widget = create_widget('file_manager')\ndisplay(file_manager_widget)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¨ Optional: LoRA Inference Preview\n",
    "\n",
    "**Test your trained LoRAs directly in the notebook!** Generate images with your LoRA and see the results instantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **OPTIONAL:** LoRA Inference Preview\n",
    "# Generate images with your trained LoRAs\n",
    "\n",
    "from widgets.inference_widget import InferenceWidget\n",
    "\n",
    "print(\"ğŸ¨ LORA INFERENCE PREVIEW\")\n",
    "print(\"âœ¨ Generate images with your trained LoRAs\")\n",
    "print()\n",
    "\n",
    "inference_widget = InferenceWidget()\n",
    "inference_widget.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‰ **Congratulations!**\n",
    "\n",
    "You've successfully trained a LoRA using the **Unified Training System**!\n",
    "\n",
    "## **âœ¨ What Just Happened**\n",
    "- Your model type was automatically detected\n",
    "- The optimal Kohya training script was selected\n",
    "- Architecture-specific optimizations were applied\n",
    "- Training used battle-tested Kohya backend code\n",
    "\n",
    "## **ğŸ¯ For Advanced Users**\n",
    "Need more control or specialized features? Check out:\n",
    "- **`Flux_SD3_Trainer.ipynb`** - T5 text encoder training, advanced Flux/SD3 features\n",
    "- **`T5_Trainer.ipynb`** - Dedicated T5 text encoder fine-tuning\n",
    "- **Future SimpleTuner notebooks** - For bleeding-edge models not supported by Kohya\n",
    "\n",
    "## **ğŸ¤ Contributing**\n",
    "Found a bug or want to add features? This project benefits from the entire community!\n",
    "\n",
    "---\n",
    "*Powered by Kohya-ss, LyCORIS, and Derrian Distro backend systems*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}