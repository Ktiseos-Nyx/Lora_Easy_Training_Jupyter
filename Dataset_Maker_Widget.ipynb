{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"assets/doro.png\" width=\"32\" height=\"32\"> Dataset Maker - LoRA Training Assistant  \n",
    "\n",
    "This notebook contains the **Dataset Widget** for preparing your training datasets.\n",
    "\n",
    "## What this notebook handles:\n",
    "- **Dataset upload** and extraction from ZIP files\n",
    "- **Image tagging** with WD14 v3 taggers or BLIP captioning\n",
    "- **Caption management** and editing\n",
    "- **Trigger word** management and injection\n",
    "- **Tag filtering** and blacklist management\n",
    "\n",
    "## Workflow:\n",
    "1. **Upload your dataset** (ZIP file or folder)\n",
    "2. **Configure tagging** settings (WD14 for anime, BLIP for photos)\n",
    "3. **Review and edit** generated captions\n",
    "4. **Add trigger words** for your LoRA\n",
    "5. **Move to training** in `Lora_Trainer_Widget.ipynb`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üìñ Dataset Preparation Guide\n\nThis comprehensive widget handles all dataset preparation tasks:\n\n### üìÅ Dataset Upload & Management\n- **Local upload**: Drag & drop ZIP files or select folders\n- **HuggingFace import**: Direct download from HF datasets\n- **Automatic extraction**: Handles ZIP, RAR, 7z archives\n- **Folder organization**: Creates proper training structure\n\n### üè∑Ô∏è Auto-Tagging Systems\n\n#### WD14 v3 Taggers (Recommended for Anime/Art)\n- **wd14-vit-v2**: General purpose, balanced accuracy\n- **wd14-convnext-v2**: Higher accuracy, slower\n- **wd14-swinv2-v2**: Best for complex scenes\n- **ONNX optimization**: 2-3x faster inference\n- **Threshold control**: Adjust tag sensitivity\n\n#### BLIP Captioning (Best for Photos/Realistic)\n- **Natural language**: Generates descriptive sentences\n- **Scene understanding**: Captures context and relationships\n- **Perfect for**: Real photos, portraits, landscapes\n\n### ‚úèÔ∏è Caption Management\n- **Bulk editing**: Apply changes to all captions\n- **Find & replace**: Update specific terms across dataset\n- **Tag frequency analysis**: See most common tags\n- **Manual editing**: Individual caption refinement\n\n### üéØ Trigger Word System\n- **Automatic injection**: Add trigger words to all captions\n- **Position control**: Beginning, end, or random placement\n- **Consistency checking**: Ensure all images have triggers\n- **Preview mode**: See changes before applying\n\n### üö´ Tag Filtering & Blacklists\n- **Quality filters**: Remove low-confidence tags\n- **Content filters**: Block unwanted content types\n- **Custom blacklists**: Your own forbidden tags\n- **Whitelist mode**: Only allow specific tags\n\n### üìà Quality Analysis\n- **Image statistics**: Resolution, format, size analysis\n- **Tag distribution**: Most/least common tags\n- **Caption length**: Optimal length recommendations\n- **Duplicate detection**: Find similar images\n\n### üí° Best Practices Tips\n\n**Dataset Size:**\n- **Characters**: 15-50 images work well\n- **Styles**: 50-200 images for consistency\n- **Concepts**: 20-100 images depending on complexity\n\n**Image Quality:**\n- **Resolution**: 768x768 minimum, 1024x1024 recommended\n- **Variety**: Different poses, angles, expressions\n- **Consistency**: Similar art style or character design\n\n### üõ†Ô∏è Recommended Image Preparation Tools\n\n**For Bulk Resizing & Cropping:**\n- **[birme.net](https://www.birme.net/)** - **Highly Recommended!**\n  - Bulk resize multiple images to exact dimensions (512x512, 1024x1024)\n  - Smart cropping with auto focal point detection\n  - Privacy-focused - images never leave your computer\n  - Perfect for dataset standardization\n\n**For Advanced Editing:**\n- **[photopea.com](https://www.photopea.com/)** - Free Photoshop alternative\n  - Browser-based, no downloads needed\n  - Full PSD support and professional tools\n  - Great for background removal, cleanup, advanced edits\n  - Perfect for preparing images before adding to dataset\n\n**Pro Tip:** Use birme.net first for bulk resizing, then photopea.com for any individual images that need special attention!\n\n**Caption Quality:**\n- **Accuracy**: Verify auto-generated tags\n- **Completeness**: Include important details\n- **Trigger words**: Use unique, memorable terms\n- **Consistency**: Same terms for same concepts"
  },
  {
   "cell_type": "markdown",
   "source": "## <img src=\"assets/OTNDORODUSKFIXED.png\" width=\"32\" height=\"32\"> 1. Environment Setup (Optional - Run if needed)\n\n**What this cell does:** Sets up the training environment if you haven't done it yet.\n\n**When to run:** \n- If this is your first time using the system\n- If you're getting \"module not found\" errors\n- If you skipped setup in the main training notebook\n\n**What happens:**\n- Downloads and installs the training backend (~10-15GB)\n- Sets up directory structure \n- Validates your system (GPU, VRAM, storage)\n\n**Skip this if:** You already ran setup in `Lora_Trainer_Widget.ipynb`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# **CELL 1A:** Environment Setup Widget (Optional)\n# Run this cell ONLY if you need to set up the training environment\n# This will download ~10-15GB and take 5-15 minutes\n\nfrom shared_managers import create_widget\nfrom sidecar import Sidecar\nimport fiftyone as fo\nfrom ipywidgets import HTML, VBox\n\n# Create persistent sidecar for dataset exploration\ndataset_explorer = Sidecar(title='üìä Dataset Explorer - FiftyOne', anchor='split-right')\n\n# Initialize and display the setup widget with shared managers\nsetup_widget = create_widget('setup')\nsetup_widget.display()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# **CELL 2:** Main Dataset Preparation Widget\n# This is THE widget for all your dataset needs - run this cell!\n\nfrom shared_managers import create_widget\n\n# Initialize and display the dataset widget with shared managers\ndataset_widget = create_widget('dataset')\ndataset_widget.display()"
  },
  {
   "cell_type": "markdown",
   "source": "## <img src=\"assets/doro.png\" width=\"32\" height=\"32\"> 2. Dataset Preparation Widget\n\n**What this cell does:** The main dataset preparation interface with all tools you need.\n\n**This widget handles:**\n- üìÅ **Dataset Upload**: ZIP files, folders, or HuggingFace URLs\n- üè∑Ô∏è **Auto-Tagging**: WD14 v3 (anime/art) or BLIP (photos)  \n- ‚úèÔ∏è **Caption Editing**: Bulk edit, find/replace, manual tweaks\n- üéØ **Trigger Words**: Add your unique trigger word to all captions\n- üö´ **Tag Filtering**: Remove unwanted tags with blacklists\n- üìä **Quality Tools**: Tag analysis, duplicate detection\n\n**How to use:**\n1. **Upload** your images (ZIP file or folder)\n2. **Configure** tagging settings for your content type\n3. **Review** and edit the generated captions\n4. **Add** your trigger word to all images\n5. **Filter** out any unwanted tags",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  <img src=\"assets/doro_fubuki.png\" width=\"32\" height=\"32\"> Dataset Preparation Checklist\n",
    "\n",
    "Before moving to training, ensure you have:\n",
    "\n",
    "### ‚úÖ Dataset Structure\n",
    "- [ ] Images are in a single folder\n",
    "- [ ] All images have corresponding .txt caption files\n",
    "- [ ] No corrupted or unreadable images\n",
    "- [ ] Consistent image format (jpg/png)\n",
    "\n",
    "### ‚úÖ Caption Quality\n",
    "- [ ] All captions contain your trigger word\n",
    "- [ ] Tags are accurate and relevant\n",
    "- [ ] No unwanted or problematic tags\n",
    "- [ ] Caption length is reasonable (50-200 tokens)\n",
    "\n",
    "### ‚úÖ Content Verification\n",
    "- [ ] Images represent what you want to train\n",
    "- [ ] Sufficient variety in poses/angles\n",
    "- [ ] Consistent quality across dataset\n",
    "- [ ] No duplicate or near-duplicate images\n",
    "\n",
    "---\n",
    "\n",
    "##  <img src=\"assets/OTNANGELDOROFIX.png\" width=\"32\" height=\"32\"> Next Steps\n",
    "\n",
    "Once your dataset is prepared:\n",
    "\n",
    "1. **Note your dataset path** - you'll need it for training\n",
    "2. **Remember your trigger word** - important for generation\n",
    "3. **Open** `Lora_Trainer_Widget.ipynb` for training setup\n",
    "4. **Run the Setup widget** first in the training notebook\n",
    "\n",
    "---\n",
    "\n",
    "## <img src=\"assets/OTNEARTHFIXDORO.png\" width=\"32\" height=\"32\"> Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**\"No images found\":**\n",
    "- Check ZIP file structure (images should be in root or single folder)\n",
    "- Verify image formats (jpg, png, webp supported)\n",
    "- Ensure files aren't corrupted\n",
    "\n",
    "**\"Tagging failed\":**\n",
    "- Check internet connection for model downloads\n",
    "- Verify sufficient disk space (2-3GB for tagger models)\n",
    "- Try different tagger model\n",
    "\n",
    "**\"Captions too long/short\":**\n",
    "- Adjust tag threshold settings\n",
    "- Use tag filtering to remove excess tags\n",
    "- Consider manual editing for important images\n",
    "\n",
    "**\"Missing trigger words\":**\n",
    "- Use bulk edit to add trigger words\n",
    "- Check trigger word injection settings\n",
    "- Verify trigger word isn't being filtered out\n",
    "\n",
    "---\n",
    "\n",
    "*Ready to create amazing LoRAs? Let's go! üöÄ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}